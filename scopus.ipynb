{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import urllib.request\n",
    "from urllib.request import urlopen, Request\n",
    "import urllib.parse\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from http.cookiejar import CookieJar\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import cchardet\n",
    "import json, os\n",
    "import pandas as pd\n",
    "from fpdf import FPDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://api.elsevier.com/content/search/scopus?\"\n",
    "\n",
    "apiKey = \"a981e389772e23df3d045cc51e2bcfc6\"\n",
    "\n",
    "query = \"TITLE-ABS-KEY ({multiple sclerosis} AND {corpus callosum})\"\n",
    "\n",
    "view = \"STANDARD\"\n",
    "\n",
    "\n",
    "try:\n",
    "    url = base_url + \"query=\" + urllib.parse.quote(query) + \"&apiKey=\" + apiKey + \"&view=\" + view\n",
    "    fetch_results = json.dumps(json.loads(urlopen(url).read()), indent=4)\n",
    "    with open(\"scopus_search_results0.json\", \"w\") as output:\n",
    "        output.write(fetch_results)\n",
    "    with open(\"scopus_search_results0.json\", \"r\") as search_results:\n",
    "        search_results = json.load(search_results)\n",
    "    total_results = int(search_results[\"search-results\"][\"opensearch:totalResults\"])\n",
    "\n",
    "    start = 26\n",
    "    int(total_results/(start-1))\n",
    "    \n",
    "    total_files = int(total_results/(start-1))\n",
    "    counter = 1\n",
    "    while counter <= total_files:\n",
    "        url = base_url + \"query=\" + urllib.parse.quote(query) + \"&apiKey=\" + apiKey + \"&view=\" + view + \"&start=\" + str(start)\n",
    "        fetch_results = json.dumps(json.loads(urlopen(url).read()), indent=4)\n",
    "        with open(f\"scopus_search_results{counter}.json\", \"w\") as output:\n",
    "            output.write(fetch_results)\n",
    "        if start+25 < total_results:\n",
    "            start += 25\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "except URLError as e:\n",
    "    print('Not found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = [None] * total_results\n",
    "titles = [None] * total_results\n",
    "links = [None] * total_results\n",
    "\n",
    "counter = 0\n",
    "while counter <= total_files:\n",
    "    with open(f\"scopus_search_results{counter}.json\", \"r\") as search_results:\n",
    "        search_results = json.load(search_results)\n",
    "    for index, entry in enumerate(search_results[\"search-results\"][\"entry\"]):\n",
    "        IDs[index+(counter*25)] = entry[\"eid\"]\n",
    "        titles[index+(counter*25)] = entry[\"dc:title\"]\n",
    "        for link in entry[\"link\"]:\n",
    "            if link[\"@ref\"] == \"scopus\":\n",
    "                links[index+(counter*25)] = entry[\"link\"][entry[\"link\"].index(link)][\"@href\"]\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = [None] * total_results\n",
    "\n",
    "for index, link in enumerate(links):\n",
    "    abstracts[index] = BeautifulSoup(urllib.request.build_opener(urllib.request.HTTPCookieProcessor(CookieJar())).open(Request(link, headers = {'User-Agent': 'Mozilla/5.0'})).read(), 'lxml').select(\"section[id = abstractSection] > p\")[0].replace_with(\"</p>\", \"\")\n",
    "    if index >= 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_list = {'IDs': IDs, 'Title': titles, 'Abstract': abstracts}\n",
    "articles_list = pd.DataFrame(articles_list)\n",
    "articles_list.to_csv(\"scopus_articles.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "193a2de7b50f61c67722eec7e6f59cff7ca8f6a70ad298197cb40762e8c17b85"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
